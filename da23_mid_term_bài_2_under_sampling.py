# -*- coding: utf-8 -*-
"""DA23. Mid-term Bài 2 Under Sampling

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1haZH83UHcrDgISma_Yjx_e9RfxyR4a7M

Bài 2. Xử lý data và dự báo (Loan Pay Off)
"""

# Commented out IPython magic to ensure Python compatibility.
import itertools
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.ticker import NullFormatter
import pandas as pd
import numpy as np
import matplotlib.ticker as ticker
from sklearn import preprocessing
from sklearn import metrics
from sklearn.metrics import classification_report
!pip install imbalanced-learn
# %matplotlib inline

#Load data từ link github/ Thông tin về ý nghĩa các biến trong bảng: https://www.kaggle.com/code/lichkeam/ibm-machine-learning-with-python-final-assignment
dataset = pd.read_csv('https://raw.githubusercontent.com/maxtran1997gmail/Files/main/loan_train.csv')

dataset

#Bước 1

dataset.info()

"""```we recognise that 'Unnamed: 0.1' is not unnecessary (the same with 'Unnamed: 0' column.```
```effective_date column and due_date column is in the wrong type of variable. it must be datetime type.```

"""

#Drop Unnamed: 0.1 column:
dataset = dataset.drop('Unnamed: 0.1', axis = 1)
#Change the type of effective and due date columns:
dataset['due_date'] = pd.to_datetime(dataset['due_date'], format = '%m/%d/%Y')
dataset['due_date'] = pd.to_datetime(dataset['due_date'], format = '%Y%m%d')
dataset['effective_date'] = pd.to_datetime(dataset['effective_date'], format = '%m/%d/%Y')
dataset['effective_date'] = pd.to_datetime(dataset['effective_date'], format = '%Y%m%d')

#Change all value in 'education' column to lower:
dataset['education']= dataset['education'].str.lower()

#Rename to similar form:
dataset = dataset.rename(columns = {'Gender':'gender','Unnamed: 0':'Unnamed'})

#print to see unique value in each column and find out more about dataset:
for i in dataset.columns:
  unique_values = dataset[i].unique()
  unique_values.sort()
  print(i)
  print(unique_values)
  print('------------')

"""`No more strange value or wrong type variable`"""

dataset

"""

```
# Code some columns: loan_status, education, gender.
```

"""

dataset['loan_status'] = np.where(dataset['loan_status']== 'PAIDOFF',1,0)
#PAIDOFF will be coded with 1, COLLECTION will be coded with 0.

dataset['education'] = np.select([dataset['education'] == 'bechalor',\
                                  dataset['education'] == 'college',\
                                  dataset['education'] == 'high school or below',\
                                  dataset['education'] == 'master or above']\
                                 , [0,1,2,3], default = 4)
#Code the 'education' column with conditions: bechalor --> 0, college --> 1, high school or below --> 2

dataset['gender'] = np.select([dataset['gender'] == 'male',\
                              dataset['gender'] == 'female'],\
                              [1,0])
#Code 'gender' column with rules: male --> 1, female --> 0

dataset.sample(5)

"""

```
Bởi vì đây là mô hình dự đoán để phân loại loan pay off,do đó ta sử dụng các phương pháp xây dựng mô hình dành cho việc phân loại (classification)
# Xây dựng mô hình dự đoán theo thứ tự:
1. Logistic regression
2. Gaussian - Naive Bayes Classification
3. Decision Tree Classification
4. Random Forest Classification
5. KNN classification
6. Support vector machine (SVM) - SVC
```

"""

#Tạo tập hợp biến X, y:
X = dataset.iloc[:,[2,3,6,7,8]]
y= dataset['loan_status']

X

"""```
#Tạo mô hình test: tập train, tập test và model predict.
```
"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)

X_train.Principal.value_counts()

y_train.value_counts()

from imblearn.under_sampling import RandomUnderSampler
X_train, y_train = RandomUnderSampler().fit_resample(X_train, y_train)
#KHi chạy lại thuật toán mới phải chạy lại từ chia tập X-train, y-train

X_train.Principal.value_counts()

y_train.value_counts()

"""1. Dùng Logistic Regression"""

from sklearn.linear_model import LogisticRegression
model_logis = LogisticRegression()
model_logis.fit(X_train,y_train)

print(classification_report(y_test,model_logis.predict(X_test)))
lr_score = float(classification_report(y_test, model_logis.predict(X_test))[94:98])
print(lr_score)

"""2. Dùng Naive Bayes Classification"""

from sklearn.naive_bayes import GaussianNB
model_GNB = GaussianNB().fit(X_train,y_train)
print(classification_report(y_test,model_GNB.predict(X_test)))

from sklearn.naive_bayes import MultinomialNB
model_MNB = MultinomialNB().fit(X_train,y_train)
y_pred_MB = model_MNB.predict(X_test)
print(classification_report(y_test, model_MNB.predict(X_test)))

from sklearn.naive_bayes import BernoulliNB
model_BNB = BernoulliNB().fit(X_train, y_train)
print(classification_report(y_test, model_BNB.predict(X_test)))

from sklearn.naive_bayes import ComplementNB
model_CNB = ComplementNB().fit(X_train, y_train)
print(classification_report(y_test,model_CNB.predict(X_test)))

NB_score = float(classification_report(y_test, model_CNB.predict(X_test))[94:98])

"""3. Dùng Decision Tree"""

from sklearn import tree
model_tree = tree.DecisionTreeClassifier(max_depth = 7)
model_tree.fit(X_train,y_train)

from sklearn.metrics import classification_report
print(classification_report(y_test, model_tree.predict(X_test)))
DT_score = float(classification_report(y_test, model_tree.predict(X_test))[94:98])

"""4.Dùng Random Forest"""

from sklearn.ensemble import RandomForestClassifier
model_RF = RandomForestClassifier(n_estimators=2, max_samples = 0.8).fit(X_train,y_train)

y_pred = model_RF.predict(X_test)
print(classification_report(y_test, y_pred))
rf_score = float(classification_report(y_test, model_RF.predict(X_test))[94:98])

"""5. Dùng KNN Classifier"""

from sklearn.neighbors import KNeighborsClassifier
model_knn = KNeighborsClassifier(n_neighbors =5).fit(X_train,y_train)

model_knn.score(X_test, y_test)

y_pred = model_knn.predict(X_test)
print(classification_report(y_test, model_knn.predict(X_test)))
knn_score = float(classification_report(y_test, model_knn.predict(X_test))[94:98])

"""6. Dùng Support Vector Machine"""

from sklearn.svm import SVC
model_svm = SVC(kernel='linear', C= 0.1, gamma=0.3, probability= True)
model_svm.fit(X_train,y_train)
print(classification_report(y_test,model_svm.predict(X_test)))
svm_score = float(classification_report(y_test, model_svm.predict(X_test))[94:98])

dict_score = {'method':['Log_reg','Nai_Bayes','DTree','RF','KNN','SVC'],
 'F1_score':(lr_score,NB_score,DT_score,rf_score,knn_score,svm_score)}

dict_score

score = pd.DataFrame(dict_score)

fig, ax = plt.subplots()
#fig = plt.figure(figsize = (9,5))
#compare.plot(x = 'method', y = 'score',kind ='scatter',ax =ax)
plt.scatter(score['method'],score['F1_score'],c = 'pink' )
for i, row in score.iterrows():
    plt.text(row['method'], row['F1_score']-0.0027 ,round(row['F1_score'],3), ha='center',va = 'top',c = 'navy')
plt.xlabel('Model Machine Learning')
plt.ylabel('F1 Score')
plt.title('F1 Score for "Collection" Value')
plt.show()

"""```
Với mục tiêu xác định các trường hợp 'collection' ta chọn những mô hình có F1 score cho '0' value cao nhất:
Logistic Regression, Bernoulli Naive Bayes, Support Vector Machine.
```

```
Với Logistic Regression, Bernoulli Naive Bayes thì gần như không thay đổi được
thông số của mô hình để mô hình dự đoán tốt hơn. Trong khi đó SVM có thể thay
đổi 1 số thông số để làm cho mô hình tốt hơn.
```
"""

from sklearn import svm, datasets
from sklearn.model_selection import GridSearchCV
iris = datasets.load_iris()

parameters={
    'C': [0.001, 0.01, 0.1, 1],
     'gamma' : [0.001, 0.01,0.1, 0.2, 0.3, 1],
     'kernel' : ['linear']#, 'poly', 'rbf', 'sigmoid']
}
svc = svm.SVC()
clf = GridSearchCV(svc, parameters)
clf.fit(X_train, y_train)
clf.best_params_

from sklearn.svm import SVC
model_svm = SVC(kernel='linear', C= 0.1, gamma=0.001, probability= True)
model_svm.fit(X_train,y_train)
print(classification_report(y_test,model_svm.predict(X_test)))
svm_score = float(classification_report(y_test, model_svm.predict(X_test))[94:98])

"""KẾT LUẬN: Chọn mô hình Complement Naive Bayes là mô hình dự đoán cho tập dữ liệu trên để dự đoán các trường hợp 'collection' tốt nhất."""