# -*- coding: utf-8 -*-
"""DA23. Mid-term Bài 3

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19rqKoF0IHYH86AAOPH6ohNMJQOlgcVN7

## Bài 3.  Dự báo Heart Disease

### I. IMPORT và hiệu chỉnh dữ liệu:
"""

import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn import svm
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.metrics import classification_report

#Import data trực tiếp từ link (data info: https://www.kaggle.com/datasets/mathurinache/cholesterol)
link='https://drive.google.com/file/d/1uv6IA63cXlvgOcvvVF6TAhY2HWZLZ8-v/view?usp=sharing'
path = 'https://drive.google.com/uc?export=download&id='+link.split('/')[-2]
dataset = pd.read_csv(path)

"""Chú ý về data set:

Cột y dự báo là cột "num" mức độ nguy cơ mắc bênh tim (-> xây dựng bài toán dự báo phân loại)

Tuy nhiên cột "chol" là dữ liệu liên tục có thể tận dụng để thực hành thêm cho các thuật toán hồi quy (có thể kết quả không tốt)
"""

dataset.sample(20)

dataset.info()

"""```
'ca' và 'thal' có kiểu dữ liệu là object cần chuyển đổi để thành kiểu int
```
"""

for i in dataset.columns:
  unique_values = dataset[i].unique()
  unique_values.sort()
  print(i)
  print(unique_values)
  print('------------')

dataset[(dataset['ca']=='?') | (dataset['thal']=='?')].shape

dataset.ca.dtypes

"""

```
#Trong cột 'ca' và 'thal' có giá trị '?' là Null ta loại bỏ  cái trị này vì chỉ có 6 hàng có giá trị này.
```

"""

dataset = dataset.drop(dataset[(dataset['ca']=='?') | (dataset['thal']=='?')].index)
dataset[['ca','thal']] = dataset[['ca','thal']].astype(int)

var_score = pd.DataFrame(dataset.corr().loc['num'].drop('num',axis = 0))
var_score.rename(columns = {'num':'corr_score'}, inplace = True)

X = dataset.drop(['num'],axis = 1)
y = dataset.num

from sklearn.preprocessing import StandardScaler
X.iloc[:,[0,3,6,12]] = StandardScaler().fit_transform(X.iloc[:,[0,3,6,12]])

y.value_counts()

"""```
Như đề bài đã yêu cầu đây là bài toán phân loại do vậy ta xem xét các mô hình học máy cho bài toán phân loại.
Theo phân tích ở trên ta thấy output y có 5 giá trị [0,1,2,3,4] dữ liệu mất cân bằng ở cái giá trị  và việc dự đoán các giá trị
có ưu tiên như nhau do đó đánh giá mô hình có thể dụa vào "độ chính xác chung".
```

#### Xử lý mất cần bằng cho tập train đẻ đảm bảo tính chính xác của dữ liệu
"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state= 1)

"""```
#Dùng over_sampling hay under_sampling để xử lý vấn đề mất cân bằng dữ liệu
```
"""

from imblearn.over_sampling import SMOTE
X_train, y_train = SMOTE().fit_resample(X_train,y_train)

y_train.value_counts()

"""
### II. CHỌN BIẾN CHO MÔ HÌNH"""

import seaborn as sns
plt.figure(figsize=(20,15))
sns.heatmap(dataset.corr(),annot=True, cmap = 'coolwarm')

from sklearn.naive_bayes import GaussianNB
for i in range(1,(X_train.shape[1]+1)):
  print(X_train.iloc[:,0:i].columns)
  model = GaussianNB().fit(X_train.iloc[:,0:i],y_train)
  print(model.score(X_test.iloc[:,0:i],y_test))
#Thử độ chính xác của mô hình khi cho từng biến vào mô hình.

var_score_1 = []
from sklearn.naive_bayes import GaussianNB
for i in range(0,X_train.shape[1]):
  model = GaussianNB().fit(X_train.iloc[:,[i]],y_train)
  #print(model.score(X_test.iloc[:,[i]],y_test))
  var_score_1.append(model.score(X_test.iloc[:,[i]],y_test))
var_score['invidual_score'] = var_score_1
var_score
#Độ chính xác khi cho duy nhất một biến vào mô hình

from sklearn.naive_bayes import GaussianNB
var_score_2 = []
for i in (X_train.columns):
  model_drop = GaussianNB().fit(X_train.drop([i],axis =1),y_train)
  model = GaussianNB().fit(X_train,y_train)
  #print(model.score(X_test,y_test) - model_drop.score(X_test.drop([i],axis =1),y_test))
  var_score_2.append(model.score(X_test,y_test) - model_drop.score(X_test.drop([i],axis =1),y_test))
var_score['drop_score'] = var_score_2
var_score
#Thử độ chính xác của mô hình khi loại một biến để xem độ chính xác thay đổi như thế nào

"""Qua nhiều lần chạy lại với những tập X_train khác nhau thì drop_score thay đổi, chứng tỏ chỉ số này không phù hợp để làm tham khảo cho việc lựa chọn biến trong data này."""

var_score['Total_score'] = var_score.mean(axis=1)
var_score

"""```
Sau khi chạy thử nghiệm khoảng 20 lần(tập train thay đổi) nhận thấy rằng biến 'fbs' fast blood sugar:
1. gây sai số tới mô hình
2. tỉ số tương quan không cao.
3. độ chính xác khi cho vào mô hình một mình rất thấp. Do đó quyết định loại
biến 'fbs' ra khỏi mô hình để đỡ phức tạp và tăng độ chính xác cho mô hình.
```

"""

X_train = X_train.drop(['fbs'],axis = 1)
X_test = X_test.drop(['fbs'], axis = 1)

"""###III. BƯỚC CHỌN MÔ HÌNH MACHINE LEARNING:
1. Mô hình logistic regression
2. Mô hình Naive-Bayes Classification
3. Mô hình Decision Tree.
4. Mô hình Random Forest.
5. Mô hình KNN
6. Mô hình SVM - SVC

Với các mô hình 3,4,5 ta tiến hành run all code 20 lần để xem xét các parameters
phù hợp với mô hình

####1.Mô hình Logistic Regression
---
"""

from sklearn.linear_model import LogisticRegression
model_lr = LogisticRegression().fit(X_train,y_train)
print(classification_report(y_test, model_lr.predict(X_test)))

"""####2.Mô hình Naive-Bayes
---
"""

from sklearn.naive_bayes import GaussianNB
model_GNB = GaussianNB().fit(X_train,y_train)
print(classification_report(y_test, model_GNB.predict(X_test)))

from sklearn.naive_bayes import BernoulliNB
model_BNB = BernoulliNB().fit(X_train,y_train)
print(classification_report(y_test, model_BNB.predict(X_test)))

"""Chọn mô hình GaussianNB cho độ chính xác tốt hơn

#### 3.Mô hình Decision Tree:
---

Tạo một file csv 'dt_score' để lưu các độ chính xác khi thay đổi max_depth với các tập giá trị khác nhau cho mỗi lần chạy lại chương trình
"""

from sklearn.tree import DecisionTreeClassifier
pd.DataFrame(list(range(1,15))).to_csv('dt_score.csv',index = False) #Chạy 1 lần
df_score = pd.read_csv('dt_score.csv')
list_score = []
for i in range (1,15):
  model_dt = DecisionTreeClassifier(max_depth = i).fit(X_train,y_train)
  list_score.append(model_dt.score(X_test,y_test))
  #print(i, model_dt.score(X_test, y_test))
df_score= pd.concat((df_score,pd.DataFrame(list_score)),axis = 1)
df_score.to_csv('dt_score.csv',index = False)
  #print(classification_report(y_test, model_dt.predict(X_test)))

df_score.iloc[:,1:len(df_score)].mean(axis = 1)

"""Sau khi cho chạy lại mô hình khoảng 20 lần t thấy max_depth = 5 là khoảng giá trị cho độ chính xác tốt nhất."""

model_dt = DecisionTreeClassifier(max_depth= 5).fit(X_train,y_train)
print(model_dt.score(X_test, y_test))

"""####4.Mô hình Random Forest:
---
"""

from sklearn.ensemble import RandomForestClassifier
#Tạo file csv một lần duy nhất ở lần chạy đầu tiên. sau đó đổi thành kiểu ghi chú
pd.DataFrame(list(range(1,20))).to_csv('rf_score.csv',index = False) #Chạy 1 lần
df_score_rf = pd.read_csv('rf_score.csv')
list_score_rf = []
for i in range (1,20):
  model_rf = RandomForestClassifier(n_estimators = i).fit(X_train,y_train)
  list_score_rf.append(model_rf.score(X_test,y_test))
  #print(model_rf.score(X_test,y_test))
df_score_rf = pd.concat((df_score_rf,pd.DataFrame(list_score_rf)),axis = 1)
df_score_rf.to_csv('rf_score.csv',index = False)

df_score_rf.iloc[:,1:len(df_score_rf)].mean(axis = 1)

"""Sau khoảng 20 lần chạy để lấy thông số thì n_estimators = 4 là giá trị tốt nhất:"""

model_rf = RandomForestClassifier(n_estimators= 4).fit(X_train, y_train)
model_rf.score(X_test,y_test)

"""####5.Mô hình KNN:
---


"""

from sklearn.neighbors import KNeighborsClassifier
#Tạo file csv một lần duy nhất ở lần chạy đầu tiên. sau đó đổi thành kiểu ghi chú
pd.DataFrame(list(range(1,15))).to_csv('knn_score.csv',index = False) #Chạy 1 lần
df_score_knn = pd.read_csv('knn_score.csv')
list_score_knn = []
for i in range (1,15):
  model_knn = KNeighborsClassifier(n_neighbors = i).fit(X_train, y_train)
  list_score_knn.append(model_knn.score(X_test,y_test))
  #print(i,model_knn.score(X_test,y_test))
df_score_knn = pd.concat((df_score_knn,pd.DataFrame(list_score_knn)),axis = 1)
df_score_knn.to_csv('knn_score.csv',index = False)

df_score_knn.iloc[:,1:len(df_score_knn)].mean(axis = 1)

"""Qua bảng trên giá trị phù hợp n_neighbors = 2"""

model_knn = KNeighborsClassifier(n_neighbors = 2).fit(X_train,y_train)

"""####6.SVC:
---
"""

from sklearn import svm
from sklearn.model_selection import GridSearchCV

parameters={
    'C': [0.001, 0.01, 0.1, 1,10],
     'gamma' : [0.001, 0.01,0.1, 0.2, 0.3, 1],
     'kernel' : ['linear','rbf']#, 'poly', 'rbf', 'sigmoid']
}
svc = svm.SVC()
clf = GridSearchCV(svc, parameters)
clf.fit(X_train, y_train)
result = clf.best_params_ #dict type

result = pd.DataFrame(result,index = [0])
result

from sklearn.svm import SVC
model_SVC = SVC(C = float(result.loc[:,'C']),
                kernel = result.kernel.iloc[0],
                gamma = float(result.gamma))
model_SVC = model_SVC.fit(X_train,y_train)
model_SVC.score(X_test,y_test)

"""###IV. Kết luận"""

#Model Logistic Regression:
lr_score = model_lr.score(X_test,y_test)
nb_score = model_GNB.score(X_test,y_test)
dt_score = model_dt.score(X_test,y_test)
rf_score = model_rf.score(X_test,y_test)
knn_score = model_knn.score(X_test,y_test)
svc_score = model_SVC.score(X_test,y_test)
dict_score = {'Model_name':['Log_Reg','Nai-Bay','Deci_Tree','Ran_Forest','KNN','SVC'],'Score':[lr_score,nb_score,dt_score,rf_score,knn_score,svc_score]}

fig, ax = plt.subplots(figsize = (8,6))
ax.set_facecolor('lightgrey')
plt.scatter(dict_score['Model_name'],dict_score['Score'],c = 'red')
value = list(dict_score.values())
for i in range(len(value[0])):
    plt.text(value[0][i], value[1][i]-0.0004 ,round(value[1][i],3), ha='center',va = 'top',c = 'navy',size=10)
plt.xlabel('Model Machine Learning')
plt.ylabel('Score')
plt.title('General Score Each Model')
plt.show()

"""###Ta chọn model KNN để dự báo cho heart desease sẽ cho độ chính xác chung là tốt nhất"""
