# -*- coding: utf-8 -*-
"""DA23. Mid- Term Bài 4

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ym_2sf_F29_dLPUTtrPhHFMv3mZlDs17

#Bài 4. Phân Loại Rượu

## I. Nạp và xử lý dữ liệu
"""

import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn import svm
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd
from sklearn.metrics import classification_report

#Thông tin về data: https://archive.ics.uci.edu/ml/datasets/wine
link='https://drive.google.com/file/d/1LeCTAusp4duAxUsrK3EfKL1p0tkTKgjY/view?usp=sharing'
path = 'https://drive.google.com/uc?export=download&id='+link.split('/')[-2]
dataset = pd.read_csv(path)

"""###1.Khám phá dữ liệu"""

dataset.info()

"""Không phát hiện giá trị nan, null.
Kiểu dữ liêu đều phù hợp với từng cột.
"""

dataset.sample(15)

for i in dataset.columns:
  unique_values = dataset[i].unique()
  unique_values.sort()
  print(i)
  print(unique_values)
  print('------------')

type(dataset.Type)

plt.hist(dataset['Phenols'],alpha = 0.5,label = 'Phenols')
plt.hist(dataset['OD'], alpha= 0.8, label = 'OD')
plt.legend()
plt.show()

X= dataset.drop(['Type'],axis = 1)
y = dataset.Type

X.columns

"""###2.Chuẩn hóa dữ liệu"""

from sklearn.preprocessing import StandardScaler
X.loc[:,['Mg','Proline']] = StandardScaler().fit_transform(X.loc[:,['Mg','Proline']])

y.value_counts()

"""Dữ liệu không quá mất cân bằng, không cần xử lý mất cân bằng dữ liệu.

###3.Chia tập train và tập test
"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.4 ,random_state =1)

"""## II. Lựa chọn biến

###1.Biểu đổ tương quan
"""

import seaborn as sns
fig,ax = plt.subplots(figsize = (6,8))
sns.heatmap(dataset.corr().loc[:,['Type']],annot = True, cmap ='Blues')
plt.show()

"""Các biến 'Ash', 'Mg', 'Color.int','Alcohol'độ tương quan hơi thấp so với các biến còn lại."""

var_score = pd.DataFrame(dataset.corr().loc['Type'].drop('Type',axis = 0))
var_score.rename(columns = {'Type':'corr_score'}, inplace = True)

"""###2.Độ chính xác của mô hình và các biến

Sử dụng 1 mô hình để kiểm độ chính xác của mô hình phụ thuộc vào các biến sẽ như thế nào
"""

from sklearn.naive_bayes import GaussianNB
for i in range(1,(X_train.shape[1]+1)):
  print(X_train.iloc[:,0:i].columns)
  model = GaussianNB().fit(X_train.iloc[:,0:i],y_train)
  print(model.score(X_test.iloc[:,0:i],y_test))
#Thử độ chính xác của mô hình khi cho từng biến vào mô hình.

var_score_1 = []
from sklearn.naive_bayes import GaussianNB
for i in range(0,X_train.shape[1]):
  model = GaussianNB().fit(X_train.iloc[:,[i]],y_train)
  #print(model.score(X_test.iloc[:,[i]],y_test))
  var_score_1.append(model.score(X_test.iloc[:,[i]],y_test))
var_score['invidual_score'] = var_score_1
var_score
#Độ chính xác khi cho duy nhất một biến vào mô hình

from sklearn.naive_bayes import GaussianNB
var_score_2 = []
for i in (X_train.columns):
  model_drop = GaussianNB().fit(X_train.drop([i],axis =1),y_train)
  model = GaussianNB().fit(X_train,y_train)
  #print(model.score(X_test,y_test) - model_drop.score(X_test.drop([i],axis =1),y_test))
  var_score_2.append(model.score(X_test,y_test) - model_drop.score(X_test.drop([i],axis =1),y_test))
var_score['drop_score'] = var_score_2
var_score
#Thử độ chính xác của mô hình khi loại một biến để xem độ chính xác thay đổi như thế nào

"""Sau nhiều lần chạy thử Các biến 'Ash', 'Mg', "Nonflavanoid.phenols' có các đặc điểm sau:
1. corrrelation độ tương quan với y không cao.
2. Độ chính xác khi cho vào mô hình duy nhất là thấp hơn so với các biến khác.
3. Độ chính xác của mô hình khi drop biến này khỏi mô hình không đổi
Do đó, ta loại 03 biến này ra khỏi mô hình.
"""

X_train = X_train.drop(['Ash','Mg','Nonflavanoid.phenols'],axis = 1)
X_test = X_test.drop(['Ash','Mg','Nonflavanoid.phenols'],axis = 1)

"""##III. Lựa chọn mô hình:
1. Mô hình logistic regression
2. Mô hình Naive-Bayes Classification
3. Mô hình Decision Tree.
4. Mô hình Random Forest.
5. Mô hình KNN
6. Mô hình SVM - SVC

###1.Logistic Regression:
"""

from sklearn.linear_model import LogisticRegression
model_lr = LogisticRegression().fit(X_train,y_train)
print(classification_report(y_test, model_lr.predict(X_test)))

"""###2.Mô hình Naive-Bayes
---
"""

from sklearn.naive_bayes import GaussianNB
model_GNB = GaussianNB().fit(X_train,y_train)
print(classification_report(y_test, model_GNB.predict(X_test)))

from sklearn.naive_bayes import BernoulliNB
model_BNB = BernoulliNB().fit(X_train,y_train)
print(classification_report(y_test, model_BNB.predict(X_test)))

"""Chọn mô hình GaussianNB cho độ chính xác tốt hơn

### 3.Mô hình Decision Tree:
---

Tạo một file csv 'dt_score' để lưu các độ chính xác khi thay đổi max_depth với các tập giá trị khác nhau cho mỗi lần chạy lại chương trình
"""

from sklearn.tree import DecisionTreeClassifier
pd.DataFrame(list(range(1,15))).to_csv('dt_score.csv',index = False) #Chạy 1 lần
df_score = pd.read_csv('dt_score.csv')
list_score = []
for i in range (1,15):
  model_dt = DecisionTreeClassifier(max_depth = i).fit(X_train,y_train)
  list_score.append(model_dt.score(X_test,y_test))
  #print(i, model_dt.score(X_test, y_test))
df_score= pd.concat((df_score,pd.DataFrame(list_score)),axis = 1)
df_score.to_csv('dt_score.csv',index = False)
  #print(classification_report(y_test, model_dt.predict(X_test)))

df_score.iloc[:,1:len(df_score)].mean(axis = 1)

"""Sau khi cho chạy lại mô hình khoảng 20 lần t thấy max_depth = 5 là khoảng giá trị cho độ chính xác tốt nhất."""

model_dt = DecisionTreeClassifier(max_depth= 5).fit(X_train,y_train)
print(model_dt.score(X_test, y_test))

"""###4.Mô hình Random Forest:
---
"""

from sklearn.ensemble import RandomForestClassifier
#Tạo file csv một lần duy nhất ở lần chạy đầu tiên. sau đó đổi thành kiểu ghi chú
pd.DataFrame(list(range(1,20))).to_csv('rf_score.csv',index = False) #Chạy 1 lần
df_score_rf = pd.read_csv('rf_score.csv')
list_score_rf = []
for i in range (1,20):
  model_rf = RandomForestClassifier(n_estimators = i).fit(X_train,y_train)
  list_score_rf.append(model_rf.score(X_test,y_test))
  #print(model_rf.score(X_test,y_test))
df_score_rf = pd.concat((df_score_rf,pd.DataFrame(list_score_rf)),axis = 1)
df_score_rf.to_csv('rf_score.csv',index = False)

df_score_rf.iloc[:,1:len(df_score_rf)].mean(axis = 1)

"""Sau khoảng 20 lần chạy để lấy thông số thì n_estimators = 4 là giá trị tốt nhất:"""

model_rf = RandomForestClassifier(n_estimators= 4).fit(X_train, y_train)
model_rf.score(X_test,y_test)

"""###5.Mô hình KNN:
---


"""

from sklearn.neighbors import KNeighborsClassifier
#Tạo file csv một lần duy nhất ở lần chạy đầu tiên. sau đó đổi thành kiểu ghi chú
pd.DataFrame(list(range(1,15))).to_csv('knn_score.csv',index = False) #Chạy 1 lần
df_score_knn = pd.read_csv('knn_score.csv')
list_score_knn = []
for i in range (1,15):
  model_knn = KNeighborsClassifier(n_neighbors = i).fit(X_train, y_train)
  list_score_knn.append(model_knn.score(X_test,y_test))
  #print(i,model_knn.score(X_test,y_test))
df_score_knn = pd.concat((df_score_knn,pd.DataFrame(list_score_knn)),axis = 1)
df_score_knn.to_csv('knn_score.csv',index = False)

df_score_knn.iloc[:,1:len(df_score_knn)].mean(axis = 1)

"""Qua bảng trên giá trị phù hợp n_neighbors = 2"""

model_knn = KNeighborsClassifier(n_neighbors = 2).fit(X_train,y_train)

"""###6.SVC:
---
"""

from sklearn import svm
from sklearn.model_selection import GridSearchCV

parameters={
    'C': [0.001, 0.01, 0.1, 1,10],
     'gamma' : [0.001, 0.01,0.1, 0.2, 0.3, 1],
     'kernel' : ['linear','rbf']#, 'poly', 'rbf', 'sigmoid']
}
svc = svm.SVC()
clf = GridSearchCV(svc, parameters)
clf.fit(X_train, y_train)
result = clf.best_params_ #dict type

result = pd.DataFrame(result,index = [0])
result

from sklearn.svm import SVC
model_SVC = SVC(C = float(result.loc[:,'C']),
                kernel = result.kernel.iloc[0],
                gamma = float(result.gamma))
model_SVC = model_SVC.fit(X_train,y_train)
model_SVC.score(X_test,y_test)

"""##IV. Kết luận"""

#Model Logistic Regression:
lr_score = model_lr.score(X_test,y_test)
nb_score = model_GNB.score(X_test,y_test)
dt_score = model_dt.score(X_test,y_test)
rf_score = model_rf.score(X_test,y_test)
knn_score = model_knn.score(X_test,y_test)
svc_score = model_SVC.score(X_test,y_test)
dict_score = {'Model_name':['Log_Reg','Nai-Bay','Deci_Tree','Ran_Forest','KNN','SVC'],'Score':[lr_score,nb_score,dt_score,rf_score,knn_score,svc_score]}

fig, ax = plt.subplots(figsize = (8,6))
ax.set_facecolor('lightgrey')
plt.scatter(dict_score['Model_name'],dict_score['Score'],c = 'red')
value = list(dict_score.values())
for i in range(len(value[0])):
    plt.text(value[0][i], value[1][i]-0.0004 ,round(value[1][i],3), ha='center',va = 'top',c = 'navy',size=10)
plt.xlabel('Model Machine Learning')
plt.ylabel('Score')
plt.title('General Score Each Model')
plt.show()

"""#Chọn mô hình Gaussian Nai-Bayes cho kết quả độ chính xác tốt nhất.
Tuy nhiên Các mô hình khác đều cho kết quả khá tốt nên vẫn có thể dùng được.
"""
